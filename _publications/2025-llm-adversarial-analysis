---
title: "WIP: From Detection to Explanation: Using LLMs for Adversarial Scenario Analysis in Vehicles"
collection: publications
permalink: /publications/2025-llm-adversarial-analysis/
date: 2025-08-10
authors:
  - David Fernandez
  - Pedram MohajerAnsari
  - Cigdem Kokenoz
  - Amir Salarpour
  - Bing Li
  - Mert D Pes√©
venue: "The 3rd USENIX Symposium on Vehicle Security and Privacy (VehicleSec '25)"
category: conference
pdf: /publications/pdfs/vehiclesec25-final74.pdf
citation: "David Fernandez, Pedram MohajerAnsari, Cigdem Kokenoz, Amir Salarpour, Bing Li, Mert D Pes√©. <i>WIP: From Detection to Explanation: Using LLMs for Adversarial Scenario Analysis in Vehicles</i>. In Proceedings of the 3rd USENIX Symposium on Vehicle Security and Privacy (VehicleSec '25), August 2025."
---

We propose a framework that leverages Large Language Models (LLMs) for **adversarial scenario analysis in autonomous vehicles (AVs)**, generating interpretable explanations for anomalies and bridging the gap between detection and semantic understanding.

Traditional deep neural networks (DNNs) lack both robustness against perception attacks and interpretability. To address this, we present a zero-shot chain-of-thought (CoT) reasoning system that uses a domain-specific language (DSL) and incorporates formal traffic knowledge from the Manual on Uniform Traffic Control Devices (MUTCD).

### üîç Key Contributions:
- **AutoSec-X**: A new dataset of 40 driving scenarios (benign and adversarial) based on MUTCD rules.
- **Zero-shot CoT prompting**: Allows LLMs to reason about adversarial situations and explain anomalies without needing labeled training data.
- **Evaluation**: Assesses LLMs (e.g., Gemini, LLaMA, Qwen) using BLEU, ROUGE, and SBERT metrics to quantify reasoning quality.

Experimental results show that larger LLMs like **Gemini 1.5-Pro** provide superior semantic reasoning and more accurate, regulation-based explanations of anomalies.

üëâ [Read the full paper (PDF)](/publications/pdfs/2025-llm-adversarial-analysis.pdf)

